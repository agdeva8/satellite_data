{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deva/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "### Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%pylab\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.signal import argrelextrema\n",
    "import statsmodels.discrete.discrete_model as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_outliers = pd.read_excel('DistrictTypes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>DistCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agra</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>4. Large City</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmadabad</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1. Metro</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>3. Capital</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ajmer</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>4. Large City</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allahabad</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>4. Large City</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     District          State           Type  DistCode\n",
       "0        Agra  Uttar Pradesh  4. Large City       146\n",
       "1   Ahmadabad        Gujarat       1. Metro       474\n",
       "2      Aizawl        Mizoram     3. Capital       283\n",
       "3       Ajmer      Rajasthan  4. Large City       119\n",
       "4  Allahabad   Uttar Pradesh  4. Large City       175"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snow_id = df_outliers[df_outliers['Type'] == '5. Snow Clad']['DistCode'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metro = df_outliers[df_outliers['Type'] == '1. Metro']['DistCode'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import Data Files\n",
    "df_satData = pd.read_csv('distSatellite_withLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asset = pd.get_dummies(pd.read_csv('District_HHD_Cluster_Asset_Labels.csv')[['District','District_HHD_Cluster_Asset']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_asset.columns = ['dist_code','asset_1','asset_2','asset_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_satData = (df_satData.merge(df_asset,left_on='101',right_on='dist_code',how='outer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_satData['dist_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_satData = df_satData[~(df_satData['101'].isin(snow_id+metro))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### List of labels\n",
    "lis_labelsAll = ['MSL_1','MSL_2','MSL_3','MSW_1','MSW_2','MSW_3','CHH_1','CHH_2','CHH_3','FC_1','FC_2','FC_3','BF_1','BF_2','BF_3','EMP_1','EMP_2','EMP_3']\n",
    "\n",
    "### List of useful Labels\n",
    "lis_labels= ['asset_1','asset_2','asset_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>101</th>\n",
       "      <th>DN_00</th>\n",
       "      <th>DN_01</th>\n",
       "      <th>DN_02</th>\n",
       "      <th>DN_03</th>\n",
       "      <th>DN_04</th>\n",
       "      <th>DN_05</th>\n",
       "      <th>DN_06</th>\n",
       "      <th>DN_07</th>\n",
       "      <th>...</th>\n",
       "      <th>FC_3</th>\n",
       "      <th>BF_1</th>\n",
       "      <th>BF_2</th>\n",
       "      <th>BF_3</th>\n",
       "      <th>EMP_1</th>\n",
       "      <th>EMP_2</th>\n",
       "      <th>EMP_3</th>\n",
       "      <th>asset_1</th>\n",
       "      <th>asset_2</th>\n",
       "      <th>asset_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adilabad</td>\n",
       "      <td>532</td>\n",
       "      <td>5237.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1815.67</td>\n",
       "      <td>3332.38</td>\n",
       "      <td>2043.90</td>\n",
       "      <td>1049.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agra</td>\n",
       "      <td>146</td>\n",
       "      <td>401.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.54</td>\n",
       "      <td>451.36</td>\n",
       "      <td>620.77</td>\n",
       "      <td>441.57</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmadabad</td>\n",
       "      <td>474</td>\n",
       "      <td>1517.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.19</td>\n",
       "      <td>1274.94</td>\n",
       "      <td>1784.85</td>\n",
       "      <td>816.68</td>\n",
       "      <td>461.02</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmadnagar</td>\n",
       "      <td>522</td>\n",
       "      <td>984.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1756.19</td>\n",
       "      <td>3855.19</td>\n",
       "      <td>2683.53</td>\n",
       "      <td>1989.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aizawl</td>\n",
       "      <td>283</td>\n",
       "      <td>3412.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.31</td>\n",
       "      <td>102.02</td>\n",
       "      <td>42.99</td>\n",
       "      <td>27.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DISTRICT  101    DN_00  DN_01  DN_02  DN_03    DN_04    DN_05    DN_06  \\\n",
       "0    Adilabad  532  5237.12      0      0   0.76  1815.67  3332.38  2043.90   \n",
       "1        Agra  146   401.66      0      0   0.00    48.54   451.36   620.77   \n",
       "2   Ahmadabad  474  1517.13      0      0  14.19  1274.94  1784.85   816.68   \n",
       "3  Ahmadnagar  522   984.52      0      0   3.12  1756.19  3855.19  2683.53   \n",
       "4      Aizawl  283  3412.59      0      0   0.00    49.31   102.02    42.99   \n",
       "\n",
       "     DN_07   ...     FC_3  BF_1  BF_2  BF_3  EMP_1  EMP_2  EMP_3  asset_1  \\\n",
       "0  1049.05   ...        0     1     0     0      0      1      0        0   \n",
       "1   441.57   ...        1     0     0     1      1      0      0        0   \n",
       "2   461.02   ...        1     0     0     1      0      0      1        0   \n",
       "3  1989.69   ...        0     1     0     0      0      1      0        0   \n",
       "4    27.32   ...        1     0     0     1      0      0      1        0   \n",
       "\n",
       "   asset_2  asset_3  \n",
       "0        1        0  \n",
       "1        1        0  \n",
       "2        0        1  \n",
       "3        1        0  \n",
       "4        0        1  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_satData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 106)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_satData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = df_satData.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_new = cols[2:cols.index('MSL_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantile_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4d4662198092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquantile_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdf_satData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_satData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mquantile_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantile_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quantile_list' is not defined"
     ]
    }
   ],
   "source": [
    "for i,quantile_val in enumerate(quantile_list):\n",
    "    df_satData.loc[df_satData[cols_new[i]] > quantile_val,cols_new[i]] = quantile_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pure_modis_features = cols[cols.index('Water'):cols.index('MSL_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building features from night light data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = []\n",
    "for i in range(64):\n",
    "    var.append('DN_' + str(i).zfill(2))\n",
    "\n",
    "df_satData['Area'] = 0\n",
    "for i in var:\n",
    "    df_satData['Area']=df_satData['Area'] + df_satData[i]\n",
    "df_satData['Area'] = df_satData['Area'].replace(0,1)\n",
    "\n",
    "for i in var:\n",
    "    df_satData['p'+i] = (df_satData[i])/(df_satData['Area']*1.0)\n",
    "\n",
    "for i,j in enumerate(var):\n",
    "    df_satData['q'+j] = df_satData[j]*(i+1)\n",
    "\n",
    "var3 = []\n",
    "for i in var:\n",
    "    var3.append('p'+i)\n",
    "for i in var:\n",
    "    var3.append('q'+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appling Pca to matrix formed from features of nightlight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_satData.loc[:,var3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43.38  60.43  68.59  72.97  76.31  78.6   80.8   82.77  84.32  85.64\n",
      "  86.87  87.94  88.82  89.59  90.26  90.89  91.43  91.89  92.33  92.74\n",
      "  93.12  93.45  93.76  94.05  94.32  94.58  94.81  95.03  95.24  95.44\n",
      "  95.64  95.83  96.01  96.18  96.35  96.51  96.67  96.82  96.96  97.1\n",
      "  97.23  97.36  97.48  97.59  97.7   97.81  97.91  98.01  98.11  98.2\n",
      "  98.29  98.38  98.47  98.55  98.63  98.7   98.77  98.84  98.91  98.98\n",
      "  99.04  99.1   99.16  99.21  99.26  99.31  99.36  99.4   99.44  99.48\n",
      "  99.51  99.54  99.57  99.6   99.63  99.66  99.68  99.7   99.72  99.74\n",
      "  99.76  99.78  99.79  99.8   99.81  99.82  99.83  99.84  99.85  99.86\n",
      "  99.87  99.88  99.89  99.9   99.91  99.92  99.93  99.94  99.95  99.96\n",
      "  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96\n",
      "  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96\n",
      "  99.96  99.96  99.96  99.96  99.96  99.96  99.96  99.96]\n",
      "('n: 95% Variance: ', 10)\n"
     ]
    }
   ],
   "source": [
    "X = preprocessing.scale(X)\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "#pca= PCA(svd_solver='full')\n",
    "#pca.fit(X, y=None )\n",
    "\n",
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)\n",
    "\n",
    "#Number of PC comprising 95%Variance\n",
    "n = len(var1)-len([num for num in var1 if num != 0 and num > 85.0])+1\n",
    "print( \"n: 95% Variance: \",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PCA fit\n",
    "X=pca.fit_transform(X)\n",
    "X=X[:,0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating variance table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pcaComp = pd.DataFrame(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_idx = ['PCA_'+str(i) for i in range(len(df_pcaComp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pcaComp.index = pca_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pcaComp.columns = var3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_pcaComp[column][:10])/abs(df_pcaComp[:10]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins_pcaVar = [[0]*10]*7\n",
    "\n",
    "for column in df_pcaComp:\n",
    "    bins_pcaVar[(int(column[4:])/10)] += (abs(df_pcaComp[column][:10])/abs(df_pcaComp[:10]).sum(axis=1))\n",
    "\n",
    "bins_pcaVar[5] += bins_pcaVar[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bins_pcaVar = pd.DataFrame(bins_pcaVar[:6]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bins_pcaVar.columns = ['L1','L2','M1','M2','H1','H2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bins_pcaVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_newVarTable = pd.DataFrame(columns=['0','1','2','3','4','5'])\n",
    "\n",
    "for i in range(10):\n",
    "    temp = df_bins_pcaVar[i:i+1].sort_values(by=pca_idx[i],axis=1,ascending=False)\n",
    "    temp_cols = temp.columns.tolist()\n",
    "    temp_vals = np.round(temp.values[0],2).tolist()\n",
    "    new_row = [str(temp_vals[j])+','+temp_cols[j] for j in range(len(temp_cols))]\n",
    "    df_newVarTable.loc[pca_idx[i],:] = new_row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_newVarTable.to_csv('newVarTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Creating Dataframe of PCA\n",
    "col_X = []\n",
    "for j in range(n):\n",
    "    col_X.append('PCA_'+str(j))\n",
    "df_pcaNTL = pd.DataFrame(X,columns=col_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pcaNTL['101'] = df_satData['101'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA_0</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.730040</td>\n",
       "      <td>-5.321751</td>\n",
       "      <td>-0.860339</td>\n",
       "      <td>3.246664</td>\n",
       "      <td>2.694576</td>\n",
       "      <td>0.809633</td>\n",
       "      <td>1.399437</td>\n",
       "      <td>-1.985949</td>\n",
       "      <td>0.947422</td>\n",
       "      <td>0.560823</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.599441</td>\n",
       "      <td>-1.433546</td>\n",
       "      <td>-0.258951</td>\n",
       "      <td>-0.041424</td>\n",
       "      <td>-0.715240</td>\n",
       "      <td>0.191611</td>\n",
       "      <td>-1.324506</td>\n",
       "      <td>1.446709</td>\n",
       "      <td>-0.833139</td>\n",
       "      <td>0.085463</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.113937</td>\n",
       "      <td>-4.310023</td>\n",
       "      <td>-7.136619</td>\n",
       "      <td>-2.049438</td>\n",
       "      <td>1.315599</td>\n",
       "      <td>1.148854</td>\n",
       "      <td>-0.142953</td>\n",
       "      <td>-1.886010</td>\n",
       "      <td>-3.099527</td>\n",
       "      <td>-1.958706</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.380082</td>\n",
       "      <td>-9.838996</td>\n",
       "      <td>1.143180</td>\n",
       "      <td>7.110819</td>\n",
       "      <td>1.978624</td>\n",
       "      <td>0.743656</td>\n",
       "      <td>3.220930</td>\n",
       "      <td>-1.526049</td>\n",
       "      <td>1.006662</td>\n",
       "      <td>0.924702</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.989618</td>\n",
       "      <td>0.675239</td>\n",
       "      <td>-0.595747</td>\n",
       "      <td>-1.363547</td>\n",
       "      <td>-0.947617</td>\n",
       "      <td>-0.620833</td>\n",
       "      <td>0.649545</td>\n",
       "      <td>0.154708</td>\n",
       "      <td>0.866108</td>\n",
       "      <td>-0.017051</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PCA_0     PCA_1     PCA_2     PCA_3     PCA_4     PCA_5     PCA_6  \\\n",
       "0   2.730040 -5.321751 -0.860339  3.246664  2.694576  0.809633  1.399437   \n",
       "1   8.599441 -1.433546 -0.258951 -0.041424 -0.715240  0.191611 -1.324506   \n",
       "2  12.113937 -4.310023 -7.136619 -2.049438  1.315599  1.148854 -0.142953   \n",
       "3   9.380082 -9.838996  1.143180  7.110819  1.978624  0.743656  3.220930   \n",
       "4  -4.989618  0.675239 -0.595747 -1.363547 -0.947617 -0.620833  0.649545   \n",
       "\n",
       "      PCA_7     PCA_8     PCA_9  101  \n",
       "0 -1.985949  0.947422  0.560823  532  \n",
       "1  1.446709 -0.833139  0.085463  146  \n",
       "2 -1.886010 -3.099527 -1.958706  474  \n",
       "3 -1.526049  1.006662  0.924702  522  \n",
       "4  0.154708  0.866108 -0.017051  283  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pcaNTL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building features out of Modis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_satData['Urban and built-up']=df_satData['Urban and built-up']+1\n",
    "df_satData['CropRatio']=(df_satData['Croplands']+df_satData['Cropland/Natural vegetation mosaic'])/df_satData['Area']\n",
    "df_satData['AvgUrbanNTL']=df_satData['sum']/df_satData['Urban and built-up']\n",
    "df_satData['UrbanRatio']= df_satData['Urban and built-up']/df_satData['Area']\n",
    "\n",
    "df_satData['Natural']= 0\n",
    "for i in ['Water','Evergreen Needleleaf forest','Evergreen Broadleaf forest','Deciduous Needleleaf forest','Deciduous Broadleaf forest','Mixed forest','Closed shrublands','Open shrublands','Woody savannas','Savannas','Grasslands','Permanent wetlands','Snow and ice']:\n",
    "    df_satData['Natural']=df_satData['Natural']+df_satData[i]\n",
    "    \n",
    "df_satData['CropRemainRatio']=(df_satData['Croplands']+df_satData['Cropland/Natural vegetation mosaic'])/(df_satData['Area']-df_satData['Natural'])\n",
    "df_satData['UrbanRemainRatio']=df_satData['Urban and built-up']/(df_satData['Area']-df_satData['Natural'])\n",
    "#df_satData['UrbanRatio']=df_satData['UrbanRatio'].fillna(0)\n",
    "\n",
    "\n",
    "forest =['Evergreen Broadleaf forest','Deciduous Broadleaf forest','Mixed forest']\n",
    "df_satData['forest'] = df_satData[forest].sum(axis=1)\n",
    "\n",
    "grass_shrubs =['Closed shrublands','Open shrublands','Woody savannas','Savannas','Grasslands']\n",
    "df_satData['grass_shrubs'] = df_satData[grass_shrubs].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modi_area = df_satData[pure_modis_features].sum(axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_area = [df_satData['Area'].values.tolist()[i]-modi_area[i] for i in range(len(df_satData))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_satData['left_area'] = left_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modi_var = []\n",
    "modi_var=['mean','sum','CropRatio', 'AvgUrbanNTL', 'UrbanRatio', 'CropRemainRatio', 'UrbanRemainRatio','Natural']\n",
    "for i in ['Croplands',\n",
    " 'Urban and built-up',\n",
    " 'Cropland/Natural vegetation mosaic',\n",
    " 'forest',\n",
    " 'grass_shrubs']:\n",
    "    df_satData['mod_'+i]=df_satData[i]/df_satData['Area']\n",
    "    modi_var.append('mod_'+i)\n",
    "    modi_var.append(i)\n",
    "#modi_var.append('left_area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final dataframe from pca version of nl and modi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_modi_nlPca =  pd.merge(df_satData[['101']+modi_var],df_pcaNTL,left_on='101',right_on='101',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 29)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modi_nlPca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = df_modi_nlPca.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding feature ranking for a particular label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureRank(label):\n",
    "    model = LogisticRegression()\n",
    "    selector = RFE(model,1, step=1)\n",
    "\n",
    "    X = df_modi_nlPca[var].values\n",
    "    X = preprocessing.scale(X)\n",
    "\n",
    "    y = df_satData.loc[:,label].values\n",
    "\n",
    "    selector.fit(X,y)\n",
    "\n",
    "    selectedIdx = selector.get_support(indices=True)\n",
    "\n",
    "    featureRanking = selector.ranking_\n",
    "\n",
    "    ranked_var = pd.DataFrame(featureRanking,var)\n",
    "    ranked_var = ranked_var.reset_index()\n",
    "    ranked_var.columns = (['var','rank'])\n",
    "    ranked_var = ranked_var.sort_values('rank')\n",
    "    ranked_var.reset_index(inplace=True)\n",
    "    del ranked_var['index']\n",
    "    \n",
    "    return ranked_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting features to maximize f1_score\n",
    "#### Assumption: Set of first n features in feature ranking will produce maximum f1_score compared to any other set of n features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectFeatures(ranked_var,label):\n",
    "    metric_list = list()\n",
    "    f1_list = list()\n",
    "    for i in range(len(ranked_var)):\n",
    "        var2 = ranked_var.loc[:i,'var'].values.tolist()\n",
    "\n",
    "        X = df_modi_nlPca.loc[:,var2].values\n",
    "        y = df_satData.loc[:,label].values\n",
    "\n",
    "        model = LogisticRegression(class_weight='balanced')\n",
    "        clf = make_pipeline(preprocessing.StandardScaler(),model)\n",
    "        predicted = cross_validation.cross_val_predict(clf,X,y, cv=5)\n",
    "\n",
    "        acc = metrics.accuracy_score(y,predicted)\n",
    "        recall = metrics.recall_score(y,predicted)\n",
    "        prec =  metrics.precision_score(y,predicted)\n",
    "\n",
    "        cm = metrics.confusion_matrix(y, predicted)\n",
    "        cm_score = float(cm[1][1])/(cm[1][1]+cm[1][0]+cm[0][1])\n",
    "\n",
    "        f1 = metrics.f1_score(y,predicted)\n",
    "\n",
    "        metric_list.append([f1,cm_score,acc,recall,prec])\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    df_metric = pd.DataFrame(metric_list)\n",
    "    df_metric.columns =  (['f1','cm','acc','recall','prec'])\n",
    "\n",
    "    ## finding the global maximum index in f1_list\n",
    "    global_maxima = f1_list.index(max(f1_list))\n",
    "\n",
    "    ## plotting f1_score with features selected\n",
    "    #figure()\n",
    "    #plt.grid()\n",
    "    #plt.plot(f1_list)\n",
    "    #plt.title(label)\n",
    "    #plt.xlabel('number of variables')\n",
    "    #plt.ylabel('f1_score')\n",
    "    \n",
    "    ## findi  ng indexes of all local maximums\n",
    "\n",
    "    x = array(f1_list)\n",
    "    # for local maxima\n",
    "    local_maxima = argrelextrema(x, np.greater)[0].tolist()\n",
    "\n",
    "    f1_acceptable = f1_list[global_maxima]-0.01\n",
    "\n",
    "    i = 0\n",
    "    while f1_list[i] < f1_acceptable:\n",
    "        i += 1\n",
    "\n",
    "    var_final = ranked_var.loc[:i,'var']\n",
    "\n",
    "    X = df_modi_nlPca.loc[:,var_final].values\n",
    "    y = df_satData.loc[:,label].values\n",
    "\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    fit = model.fit(X,y)\n",
    "\n",
    "    df_selecedVar = ranked_var.loc[:i].copy(deep=True)\n",
    "    df_selecedVar.insert(2,'coeff',fit.coef_[0])\n",
    "\n",
    "    return [df_selecedVar,f1_list[i],df_metric[i:i+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deva/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "select_feature = []\n",
    "score_metric = []\n",
    "for label in lis_labels:\n",
    "    ranked_var = featureRank(label)\n",
    "    feature_and_score = selectFeatures(ranked_var,label)\n",
    "    select_feature.append(feature_and_score)\n",
    "    score_metric.append(feature_and_score[2].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scoreMetric = pd.DataFrame(score_metric,columns = ['f1','cm','acc','recall','prec'], index=lis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_scoreMetric.to_csv('scoreMetric_asset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>cm</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asset_1</th>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.654987</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.883636</td>\n",
       "      <td>0.716814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_2</th>\n",
       "      <td>0.679054</td>\n",
       "      <td>0.514066</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.681356</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_3</th>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.530973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1        cm       acc    recall      prec\n",
       "asset_1  0.791531  0.654987  0.800000  0.883636  0.716814\n",
       "asset_2  0.679054  0.514066  0.703125  0.681356  0.676768\n",
       "asset_3  0.655738  0.487805  0.901563  0.857143  0.530973"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scoreMetric.sort_values(by='f1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "select_feature[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## adding pvalues.... to the list of featues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_modi_nlPca.copy(deep=True)\n",
    "X.insert(1,'intercept',1.0)\n",
    "cols = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modi_cols = cols[1:cols.index('PCA_0')]\n",
    "pca_cols = ['intercept'] + cols[cols.index('PCA_0'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_summary(cols,label):\n",
    "    X1 = X[cols].values\n",
    "    y = df_satData.loc[:,label].values\n",
    "\n",
    "    model = sm.Logit(y,X1)\n",
    "    result = model.fit()\n",
    "    summary = result.summary()\n",
    "\n",
    "    df_summary = pd.DataFrame(result.params,result.pvalues)\n",
    "    df_summary.reset_index(inplace=True)\n",
    "    df_summary.index = cols\n",
    "    df_summary.columns = ['pvals','param']\n",
    "    \n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectedFeatures_pval = []\n",
    "for i,label in enumerate(lis_labelsAll):\n",
    "    df_temp = select_feature[i][0].copy(deep=True)\n",
    "    df_temp.index = df_temp['var']\n",
    "    del df_temp['var']\n",
    "    df_summary = pd.concat([find_summary(modi_cols,label),find_summary(pca_cols,label)])\n",
    "    df_temp2 = pd.concat([df_temp,df_summary],axis=1,join_axes=[df_temp.index])\n",
    "    selectedFeatures_pval.append(df_temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = 'BF_1'\n",
    "selectedFeatures_pval[lis_labelsAll.index(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
